---
title: 机器学习模型的评估与选择
date: 2018-02-10 21:17:06
categories: 
- MachineLearning
---


### 误差

错误率：在m个样本中a个分类错误，则错误率E=a/m；精度=1-错误率。

误差：学习器预测输出与真实输出之间的差异，包括训练误差（又称为经验误差）、泛化误差（在新样本产生的误差）。

### 过拟合问题

学习器当然误差越小越好，然而即便训练误差很小，但此类学习器不一定是最好的，因为泛化误差的存在。好的学习器一定是训练误差和泛化误差都较小。

泛化误差是无法彻底消除的，只能通过一定的手段抑制。由此就产生了过拟合和欠拟合的问题。

· 过拟合：把训练样本自身的特点当作所有样本都具有的特质，导致泛化能力下降。
· 欠拟合：对训练样本自身特性都没有学习好。

欠拟合比较容易克服，通常采用增加训练轮数、扩展分支等方法。

过拟合是机器学习面临的关键障碍，但无法彻底避免。

### 选择测试集的方法

为了评估泛化误差，需要在数据集中选出“测试集”来测试学习器的判别能力，以测试集的“测试误差”作为泛化误差的近似。

常见选择测试集的方法有三类：

1. 留出法
直接将数据集D分类互斥的两个子集，一个作为训练数据集，另一个作为测试数据集。
**注意：** 划分时保持数据分布的一致性，按比例分层采样。此外，一般采用若干次随机划分、重复实验评估取均值的方法。
2. 交叉验证法
将数据集分为k个大小相似的互斥子集，每个子集均通过分层采样得到。每一次用k-1个子集训练，另外一个测试，获得k组数据集进行k次训练，取均值。
采用不同的子集划分方法重复p次，最终结果为p次k折交叉验证的结果均值。
**特例：** 留一法，即数据集m个，分成k个子集，k=m。优点是能获得与数据集D最相近的学习结果，缺点是在大数据量的数据集上计算量很大，实现难度大。
3. 自助法
给定包含m个样本的数据集D，每次随机从D中挑一个，拷贝后放回，重复m次得到m个样本数据集d。

> **方法1与2更常用。**

### 性能度量

性能度量分为回归任务和分类任务两类。

对于回归任务，性能度量方式为均方误差。

对于分类任务，有4种性能度量方法：

1. 错误率与精度

2. 查全率与查准率
预测结果是正例的样本中，真值为正例的为真正例TP，真值为反例的为假正例FP；
预测结果是反例的样本中，真值为反例的为真反例TN，真值为正例的为假反例FN。
查准率P=TP/(TP+FP)
查全率R=TP/(TP+FN)
查准率高时，查全率低；反之亦然。以查准率为纵轴、查全率为横轴生成“P-R图”。图中，若一个学习器被另一个完全包住，则另一个学习器全面更优。若两个学习器曲线交叉，通过平衡点或F1指数判断。（详见P32）

3. ROC与AUC
ROC全称“受试者工作特征”，用来研究学习器的泛化性能。其中：
纵轴为真正例率（真值为正例的样本中，预测正确的比例）TPR=TP/(TP+FN)
横轴为假正例率（真值为反例的样本中，预测为正例的比例）FPR=FP/(TN+FP)
根据曲线所包围的面积大小判断学习器泛化性能的优劣，即AUC。

4. 代价敏感错误率与错误曲线
在计算误差是考虑误检测代价，实际上是为检测结果加了权重。
代价重要的是不同误检测结果的代价比例，而非代价的绝对值。

### 比较检验

采用统计假设检验。

### 偏差与方差

泛化误差可以分解为偏差、方差、噪声之和。